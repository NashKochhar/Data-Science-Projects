{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a03a01a",
   "metadata": {},
   "source": [
    "### This file was used for extraction and transformation. It is used to create dimension and fact tables which is then loaded into the datawarehouse using the bulk query file. \n",
    "\n",
    "Step 1: Create database and tables using the SQL Files, create_database file, create_table_relations file in order.\n",
    "Step 2. Run this file to obtain dimension and fact tables. Then run Bulk_Query sql file to populate tables.\n",
    "Or use the pre-existing files in the csv files folder after step one. This script will create the same files as the csv files folder.Then run Bulk_Query sql file to populate tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7fabdc",
   "metadata": {},
   "source": [
    "### Data Reading and combining databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "067b0028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_seek = pd.read_csv('seek_australia.csv')\n",
    "df_reed=pd.read_csv('reed_uk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87ba401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_job_df = pd.concat([df_seek, df_reed], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3129afc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>city</th>\n",
       "      <th>company_name</th>\n",
       "      <th>geo</th>\n",
       "      <th>job_board</th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_type</th>\n",
       "      <th>post_date</th>\n",
       "      <th>salary_offered</th>\n",
       "      <th>state</th>\n",
       "      <th>url</th>\n",
       "      <th>job_requirements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>science jobs</td>\n",
       "      <td>Oxfordshire</td>\n",
       "      <td>Hays Specialist Recruitment Limited</td>\n",
       "      <td>uk</td>\n",
       "      <td>reed</td>\n",
       "      <td>Apply now Scientist - Cell Based Assays - Neu...</td>\n",
       "      <td>Scientist In vitro Cell-Free &amp; Cell Based Assays</td>\n",
       "      <td>Contract, full-time</td>\n",
       "      <td>3/7/2018</td>\n",
       "      <td>£22.00 - £26.00 per hour</td>\n",
       "      <td>South East England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>graduate training internships jobs</td>\n",
       "      <td>Northampton</td>\n",
       "      <td>The Graduate</td>\n",
       "      <td>uk</td>\n",
       "      <td>reed</td>\n",
       "      <td>Apply now Our client is looking for high achi...</td>\n",
       "      <td>Graduate Training Scheme - Recruitment</td>\n",
       "      <td>Permanent, full-time</td>\n",
       "      <td>3/9/2018</td>\n",
       "      <td>£18,000 - £21,000 per annum</td>\n",
       "      <td>Northamptonshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Required skills Blue Chip Communication Skill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>strategy consultancy jobs</td>\n",
       "      <td>City of London</td>\n",
       "      <td>Capgemini Consulting</td>\n",
       "      <td>uk</td>\n",
       "      <td>reed</td>\n",
       "      <td>Apply on employer's website Who youâ€™ll be w...</td>\n",
       "      <td>Management Consultant - Retail Buying, Merchan...</td>\n",
       "      <td>Permanent, full-time</td>\n",
       "      <td>2/17/2018</td>\n",
       "      <td>Competitive salary</td>\n",
       "      <td>London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>purchasing jobs</td>\n",
       "      <td>Egham</td>\n",
       "      <td>Concept Human Solutions</td>\n",
       "      <td>uk</td>\n",
       "      <td>reed</td>\n",
       "      <td>Apply now UNDERSTANDING, SERVICE, TRUST3 Word...</td>\n",
       "      <td>AV Procurement Assistant</td>\n",
       "      <td>Permanent, full-time</td>\n",
       "      <td>3/6/2018</td>\n",
       "      <td>£27,500 - £30,000 per annum, negotiable, OTE</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Required skills Procurement AV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>fmcg jobs</td>\n",
       "      <td>London</td>\n",
       "      <td>D R Newitt</td>\n",
       "      <td>uk</td>\n",
       "      <td>reed</td>\n",
       "      <td>Apply now My client, highly successful, rapid...</td>\n",
       "      <td>Supply Planner - French Speaking</td>\n",
       "      <td>Permanent, full-time</td>\n",
       "      <td>2/27/2018</td>\n",
       "      <td>£45,000 per annum</td>\n",
       "      <td>South East England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Required skills FMCG French Supply Planning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 category            city  \\\n",
       "49995                        science jobs     Oxfordshire   \n",
       "49996  graduate training internships jobs     Northampton   \n",
       "49997           strategy consultancy jobs  City of London   \n",
       "49998                     purchasing jobs           Egham   \n",
       "49999                           fmcg jobs          London   \n",
       "\n",
       "                               company_name geo job_board  \\\n",
       "49995  Hays Specialist Recruitment Limited   uk      reed   \n",
       "49996                         The Graduate   uk      reed   \n",
       "49997                 Capgemini Consulting   uk      reed   \n",
       "49998              Concept Human Solutions   uk      reed   \n",
       "49999                           D R Newitt   uk      reed   \n",
       "\n",
       "                                         job_description  \\\n",
       "49995   Apply now Scientist - Cell Based Assays - Neu...   \n",
       "49996   Apply now Our client is looking for high achi...   \n",
       "49997   Apply on employer's website Who youâ€™ll be w...   \n",
       "49998   Apply now UNDERSTANDING, SERVICE, TRUST3 Word...   \n",
       "49999   Apply now My client, highly successful, rapid...   \n",
       "\n",
       "                                               job_title  \\\n",
       "49995   Scientist In vitro Cell-Free & Cell Based Assays   \n",
       "49996             Graduate Training Scheme - Recruitment   \n",
       "49997  Management Consultant - Retail Buying, Merchan...   \n",
       "49998                           AV Procurement Assistant   \n",
       "49999                  Supply Planner - French Speaking    \n",
       "\n",
       "                   job_type  post_date  \\\n",
       "49995   Contract, full-time   3/7/2018   \n",
       "49996  Permanent, full-time   3/9/2018   \n",
       "49997  Permanent, full-time  2/17/2018   \n",
       "49998  Permanent, full-time   3/6/2018   \n",
       "49999  Permanent, full-time  2/27/2018   \n",
       "\n",
       "                                       salary_offered               state  \\\n",
       "49995                       £22.00 - £26.00 per hour   South East England   \n",
       "49996                    £18,000 - £21,000 per annum     Northamptonshire   \n",
       "49997                             Competitive salary               London   \n",
       "49998   £27,500 - £30,000 per annum, negotiable, OTE               Surrey   \n",
       "49999                              £45,000 per annum   South East England   \n",
       "\n",
       "       url                                   job_requirements  \n",
       "49995  NaN                                                NaN  \n",
       "49996  NaN   Required skills Blue Chip Communication Skill...  \n",
       "49997  NaN                                                NaN  \n",
       "49998  NaN                    Required skills Procurement AV   \n",
       "49999  NaN       Required skills FMCG French Supply Planning   "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_job_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75698d9",
   "metadata": {},
   "source": [
    "## Data Cleaning of dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f4bdfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf=combined_job_df.fillna(\"NOT LISTED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054267e0",
   "metadata": {},
   "source": [
    "#### Date Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f7611fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Grab the date part\n",
    "def dateclean(str):\n",
    "    if 'T' in str:\n",
    "        new_str=str.replace(str,str.split('T')[0])\n",
    "        str=str.replace(str,new_str)\n",
    "    return str          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "481d4252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2018-04-15\n",
       "1       2018-04-15\n",
       "2       2018-04-15\n",
       "3       2018-04-16\n",
       "4       2018-04-16\n",
       "           ...    \n",
       "49995   2018-03-07\n",
       "49996   2018-03-09\n",
       "49997   2018-02-17\n",
       "49998   2018-03-06\n",
       "49999   2018-02-27\n",
       "Name: new_post_date, Length: 80000, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## New df contains combined seek and reed database.\n",
    "\n",
    "newdf['post_date']=newdf['post_date'].apply(dateclean)\n",
    "newdf['new_post_date']=pd.to_datetime(newdf['post_date'])\n",
    "newdf['new_post_date']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071e5966",
   "metadata": {},
   "source": [
    "### Job Title cleaning function applied later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf11166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_titles(str):\n",
    "    \n",
    "    cha_lst=['-','/',',','+','@','(','â€“','&',\"?\",':','.','|','and','full','Full','part','Part']\n",
    "    for char in cha_lst:\n",
    "        if char in str:\n",
    "            new_str=str.replace(str,str.split(char)[0])\n",
    "            if len(new_str)>10:\n",
    "                str=str.replace(str,new_str)   \n",
    "    \n",
    "    return re.sub(r'[^A-Za-z0-9 ]+','',str) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5c35df",
   "metadata": {},
   "source": [
    "#### Category cleaning function applied later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57371c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cat(str):\n",
    "  \n",
    "    if 'catering' in str.lower():\n",
    "            str=str.replace(str,'Hospitality  Tourism')\n",
    "    elif 'law' in str.lower():\n",
    "            str=str.replace(str,'Legal')\n",
    "    elif 'factory' in str.lower():\n",
    "            str=str.replace(str,'Trades  Services')\n",
    "    \n",
    "    elif 'retail' in str.lower():\n",
    "            str=str.replace(str,'Retail  Consumer Products')\n",
    "    \n",
    "    elif 'hr jobs' in str.lower():\n",
    "            str=str.replace(str,'Human Resources  Recruitment')\n",
    "    \n",
    "    elif 'marketing' in str.lower():\n",
    "            str=str.replace(str,'Marketing  Communications')\n",
    "    \n",
    "    elif 'estate' in str.lower():\n",
    "            str=str.replace(str,'Real Estate  Property')\n",
    "    \n",
    "    elif 'customer' in str.lower():\n",
    "            str=str.replace(str,'Call Centre  Customer Service')\n",
    "    \n",
    "    elif 'account' in str.lower():\n",
    "            str=str.replace(str,'Accounting')\n",
    "\n",
    "    elif 'health' in str.lower():\n",
    "            str=str.replace(str,'Healthcare  Medical')\n",
    "    \n",
    "    elif 'logistics' in str.lower():\n",
    "            str=str.replace(str,'Manufacturing Transport  Logistics')\n",
    "    \n",
    "    elif 'social' in str.lower():\n",
    "            str=str.replace(str,'Community Services  Development')\n",
    "                    \n",
    "    elif 'bank' in str.lower() or 'finance' in str.lower():\n",
    "            str=str.replace(str,'Banking  Financial Services')\n",
    "\n",
    "    elif 'recruitment' in str.lower():\n",
    "            str=str.replace(str,'Human Resources  Recruitment')\n",
    "    \n",
    "    elif 'engineering' in str.lower():\n",
    "            str=str.replace(str,'Engineering')\n",
    "\n",
    "    elif 'construction' in str.lower():\n",
    "            str=str.replace(str,'Construction')\n",
    "                    \n",
    "    elif 'admin' in str.lower():\n",
    "            str=str.replace(str,'Administration  Office Support')\n",
    "\n",
    "    elif 'sales' in str.lower():\n",
    "            str=str.replace(str,'Sales')\n",
    "    \n",
    "    elif 'it jobs' in str.lower():\n",
    "            str=str.replace(str,'Information  Communication Technology')\n",
    "\n",
    "    elif 'education' in str.lower():\n",
    "            str=str.replace(str,'Education  Training')\n",
    "    ###\n",
    "    elif 'energy' in str.lower():\n",
    "            str=str.replace(str,'Mining Resources  Energy')\n",
    "\n",
    "    elif 'apprenticeships jobs' in str.lower():\n",
    "            str=str.replace(str,'Apprenticeships, Training and Internships')\n",
    "    \n",
    "    elif 'training' in str.lower():\n",
    "            str=str.replace(str,'Apprenticeships, Training and Internships')\n",
    "    \n",
    "    elif 'graduate' in str.lower():\n",
    "           \n",
    "            str=str.replace(str,'Apprenticeships, Training and Internships')\n",
    "\n",
    "    elif 'charity' in str.lower():\n",
    "            str=str.replace(str,'Community Services  Development')\n",
    "    ##\n",
    "    elif 'strategy' in str.lower():\n",
    "            str=str.replace(str,'Consulting  Strategy')\n",
    "    \n",
    "    elif 'fmcg jobs' in str.lower():\n",
    "            str=str.replace(str,'Retail  Consumer Products')\n",
    "\n",
    "    elif 'leisure' in str.lower():\n",
    "            str=str.replace(str,'Hospitality  Tourism')\n",
    "    \n",
    "    ##\n",
    "    \n",
    "    elif 'insurance' in str.lower():\n",
    "            str=str.replace(str,'Insurance  Superannuation')\n",
    "\n",
    "    elif 'media' in str.lower():\n",
    "            str=str.replace(str,'Advertising Arts  Media')\n",
    "\n",
    "    \n",
    "    elif 'science' in str.lower():\n",
    "            str=str.replace(str,'Science  Technology')\n",
    "\n",
    "    \n",
    "    elif 'motoring' in str.lower():\n",
    "            str=str.replace(str,'Manufacturing Transport  Logistics')\n",
    "\n",
    "    elif 'security' in str.lower():\n",
    "            str=str.replace(str,'Trades  Services')\n",
    "\n",
    "    str=str.replace('jobs',\"\")\n",
    "    return re.sub(r'[^A-Za-z0-9 ]+','',str) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec9c668",
   "metadata": {},
   "source": [
    "### General cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "613a200b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genclean(str):\n",
    "    return re.sub(r'[^A-Za-z0-9 ]+','',str) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077a5c7a",
   "metadata": {},
   "source": [
    "## Clean Dataframe with cleaning functions applied to relevant attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce457120",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df=pd.DataFrame()\n",
    "\n",
    "clean_df['job_title']=newdf['job_title'].apply(clean_titles)\n",
    "clean_df['category']=newdf['category'].apply(clean_cat)\n",
    "clean_df['state']=newdf['state'].apply(genclean)\n",
    "clean_df['job_type']=newdf['job_type'].apply(genclean)\n",
    "clean_df['geo']=newdf['geo'].apply(genclean)\n",
    "clean_df['company_name']=newdf['company_name'].apply(genclean)\n",
    "clean_df['city']=newdf['city'].apply(genclean)\n",
    "\n",
    "clean_df['year']=newdf['new_post_date'].dt.year\n",
    "clean_df['month']=newdf['new_post_date'].dt.month\n",
    "clean_df['day']=newdf['new_post_date'].dt.day\n",
    "clean_df['new_post_date']=newdf['new_post_date']\n",
    "clean_df['month_name']=newdf['new_post_date'].dt.month_name()\n",
    "clean_df['day_name']=newdf['new_post_date'].dt.day_name()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f664c490",
   "metadata": {},
   "source": [
    "#### Location Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6195246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      geo                       city                           state  LOC_SK\n",
      "0      AU                     Sydney   North Shore  Northern Beaches       1\n",
      "1      AU                   Brisbane                Northern Suburbs       2\n",
      "2      AU                     Sydney     Parramatta  Western Suburbs       3\n",
      "3      AU                  Melbourne  Bayside  South Eastern Suburbs       4\n",
      "4      AU                   Adelaide                      NOT LISTED       5\n",
      "...    ..                        ...                             ...     ...\n",
      "49788  uk             Skipton Bridge                 North Yorkshire    3432\n",
      "49822  uk                   Tredegar                           Wales    3433\n",
      "49870  uk                   Melbourn                   Hertfordshire    3434\n",
      "49926  uk                 Somercotes                      Derbyshire    3435\n",
      "49932  uk  Astmoor Industrial Estate                        Cheshire    3436\n",
      "\n",
      "[3436 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df = clean_df[['geo','city','state']].drop_duplicates()\n",
    "df['LOC_SK'] = range(1,len(df.index)+1)\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ee5b37",
   "metadata": {},
   "source": [
    "### Location Dimension to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cec0afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('DimLocation.csv',columns=['LOC_SK','geo','state','city'],index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915ade97",
   "metadata": {},
   "source": [
    "#### Date Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f92565a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      new_post_date  year month_name  month   day_name  day  DATE_SK\n",
      "0        2018-04-15  2018      April      4     Sunday   15        1\n",
      "3        2018-04-16  2018      April      4     Monday   16        2\n",
      "4409     2018-04-17  2018      April      4    Tuesday   17        3\n",
      "8127     2018-04-14  2018      April      4   Saturday   14        4\n",
      "11389    2018-04-13  2018      April      4     Friday   13        5\n",
      "...             ...   ...        ...    ...        ...  ...      ...\n",
      "43956    2018-01-08  2018    January      1     Monday    8       70\n",
      "47269    2017-12-28  2017   December     12   Thursday   28       71\n",
      "48175    2018-01-10  2018    January      1  Wednesday   10       72\n",
      "48634    2018-02-04  2018   February      2     Sunday    4       73\n",
      "48767    2018-01-25  2018    January      1   Thursday   25       74\n",
      "\n",
      "[74 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "df1 = clean_df[['new_post_date','year','month_name','month','day_name','day']].drop_duplicates()\n",
    "df1['DATE_SK'] = range(1,len(df1.index)+1)\n",
    "print (df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54dcd82",
   "metadata": {},
   "source": [
    "### Date Dimension to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9eaac65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('DimDate.csv',columns=['DATE_SK','new_post_date','year','month_name','month','day_name','day'],index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa1ccd7",
   "metadata": {},
   "source": [
    "#### Company Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e45856f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            company_name                   category  COMP_SK\n",
      "0      Frontline Executive Retail Sydney  Retail  Consumer Products        1\n",
      "1                              Powerlink        Government  Defence        2\n",
      "2                    Richard Jay Laundry           Trades  Services        3\n",
      "3                      Adaptalift Hyster           Trades  Services        4\n",
      "4                      Bakers Delight GM           Trades  Services        5\n",
      "...                                  ...                        ...      ...\n",
      "49964          Jonathan Lee Recruitment        Consulting  Strategy    25617\n",
      "49975                 Willis Global Ltd        Consulting  Strategy    25618\n",
      "49987                             Elite                 purchasing     25619\n",
      "49992             St Andrews Healthcare                 purchasing     25620\n",
      "49998           Concept Human Solutions                 purchasing     25621\n",
      "\n",
      "[25621 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df2 = clean_df[['company_name','category']].drop_duplicates()\n",
    "df2['COMP_SK'] = range(1,len(df2.index)+1)\n",
    "print (df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51514253",
   "metadata": {},
   "source": [
    "### Company Dimension to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7355f36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('DimCompany.csv',columns=['COMP_SK','category','company_name'],index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f5bf72",
   "metadata": {},
   "source": [
    "#### Job Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2388946b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 job_type                           job_title  JOB_SK\n",
      "0               Full Time                      Store Manager        1\n",
      "1               Full Time             Client Solution Analyst       2\n",
      "2               Full Time                 Service Technician        3\n",
      "3               Full Time    Workshop Technician I Material H       4\n",
      "4               Full Time         APPRENTICESHIP JUNIOR BAKER       5\n",
      "...                   ...                                 ...     ...\n",
      "49985  Permanent fulltime                    Head of Networks   42139\n",
      "49987  Permanent fulltime  Logistics and Operations Assistant   42140\n",
      "49992  Permanent fulltime            Strategic Sourcing Buyer   42141\n",
      "49995   Contract fulltime             Scientist In vitro Cell   42142\n",
      "49998  Permanent fulltime            AV Procurement Assistant   42143\n",
      "\n",
      "[42143 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df3 = clean_df[['job_type','job_title']].drop_duplicates()\n",
    "df3['JOB_SK'] = range(1,len(df3.index)+1)\n",
    "print (df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9bf520",
   "metadata": {},
   "source": [
    "### Job Dimension to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6de11d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv('DimJob.csv',columns=['JOB_SK','job_type','job_title'],index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5493e0e",
   "metadata": {},
   "source": [
    "## Merging Dimensions dataframes and original clean dataframe to obtain the fact table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "020383e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB_SK</th>\n",
       "      <th>COMP_SK</th>\n",
       "      <th>LOC_SK</th>\n",
       "      <th>DATE_SK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>42142</td>\n",
       "      <td>20355</td>\n",
       "      <td>153</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>32094</td>\n",
       "      <td>21221</td>\n",
       "      <td>182</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>29745</td>\n",
       "      <td>20092</td>\n",
       "      <td>200</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>42143</td>\n",
       "      <td>25621</td>\n",
       "      <td>1030</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>29707</td>\n",
       "      <td>20057</td>\n",
       "      <td>100</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       JOB_SK  COMP_SK  LOC_SK  DATE_SK\n",
       "0           1        1       1        1\n",
       "1           2        2       2        1\n",
       "2           3        3       3        1\n",
       "3           4        4       4        2\n",
       "4           5        5       5        2\n",
       "...       ...      ...     ...      ...\n",
       "79995   42142    20355     153       17\n",
       "79996   32094    21221     182       19\n",
       "79997   29745    20092     200       54\n",
       "79998   42143    25621    1030       16\n",
       "79999   29707    20057     100       11\n",
       "\n",
       "[80000 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact=pd.DataFrame()\n",
    "new1_df = pd.merge(clean_df, df3,  how='left', left_on=['job_type','job_title'], right_on = ['job_type','job_title'])\n",
    "new2_df = pd.merge(clean_df, df2,  how='left', left_on=['category','company_name'], right_on = ['category','company_name'])\n",
    "new3_df = pd.merge(clean_df, df,  how='left', left_on=['geo','city','state'], right_on =['geo','city','state'])\n",
    "new4_df = pd.merge(clean_df, df1,  how='left', left_on=['new_post_date','year','month_name','month','day_name','day'] ,right_on =['new_post_date','year','month_name','month','day_name','day'])\n",
    "fact['JOB_SK']=new1_df['JOB_SK']\n",
    "fact['COMP_SK']=new2_df['COMP_SK']\n",
    "fact['LOC_SK']=new3_df['LOC_SK']\n",
    "fact['DATE_SK']=new4_df['DATE_SK']\n",
    "\n",
    "fact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db8da20",
   "metadata": {},
   "source": [
    "### Fact table to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7878e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact.to_csv('FactlessJob.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b63b836d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Optional\n",
    "#clean_df.to_csv('clean.csv',index=False,header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
